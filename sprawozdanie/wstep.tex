\section{Wstęp: }
\subsection{Algorytm k-random}
  Algorytm k-random polega na wygenerowaniu losowego dopuszczalnego rozwiązania (co w naszym przypadku, gdzie wszystkie grafy są gęste, oznacza wybranie losowej permutacji wierzchołków) i wyznaczenie dla niego funkcji celu. Ów schemat powtarzamy k razy, z czego wybieramy najmniejszą drogę co do wartości.

  \textbf{Złożoność obliczeniowa:} Procedura \textit{k-random} wykonuje n razy funkcję \textit{cost}, która działa w czasie liniowym. Dodatkowo do generowania nowych rozwiązań korzystamy z wbudowanej biblioteki pythona o nazwie \textit{random}, która zawiera funkcję \textit{shuffle}, której złożoność obliczeniowa wynosi O(n), gdyż korzysta z \textbf{"Fisher–Yates-shuffle"}. Ostatecznie więc, złożoność obliczeniowa tej metody wynosi $O(k*n)$.

  \textbf{Złożoność pamięciowa: } Procedura \textit{k-random} generuje n-elementową permutację wierzchołków w formie listy. Następnie w specjalnej zmiennej przechowywana jest lista o najmniejszej funkcji celu, stąd ostatecznie nasza funkcje składa się z dwóch list o długości n. Wniosek: O(n)

\subsection{Algorytm najbliższego sąsiada: omówienie}
  Algorytm najbliższego sąsiada jest algorytmem z grupy algorytmów zachłannych- wybiera lokalnie najlepsze rozwiązanie, w ten sposób budując pełne rozwiązanie. 

  \textbf{Złożoność obliczeniowa:} Procedura \textit{nearestneighbor} wykonuje się aż do momentu, gdy cała lista \textit{path} zostanie zapełniona. W każdym kroku dodajemy do niej jeden wierzchołek, więc zewnętrzny while wykonuje się dokładnie n razy. Następnie wewnątrz while'a przechodzimy liniowo po strukturze w poszukiwaniu sąsiada, do której jeszcze nie dotarliśmy(złożoność liniowa), jednakże dodatkowo dokonuje sortowania wierzchołków w celu ułatwienia iterowania po sąsiadach. Do sortowania korzystamy z wbudowanej funkcji \textit{sorted}, która wykonuje się w czasie $O(n*logn)$. Ostatecznie otrzymujemy złożonośc obliczeniową worst-case na poziomie $O(n^{2}*logn)$.

  \textbf{Złożoność pamięciowa: }
    Wewnątrz algorytmu dokonujemy tworzenia dodatkowe słownika, stąd wnioskujemy, iz złożnośc pamięciowa tego algorytmu jest równa O(n).
\subsection{Algorytm rozszerzonego najbliższego sąsiada: omówienie}
  Algorytm rozszerzonego najbliższego sąsiada polega na oduzależnieniu działania algorytmu od wyboru wierzchołka początkowego poprzez wykonanie podstawowego sąsiada dla wszystkich wierzchołków startowych
  \textbf{Złożność: }
    Algorytm wykorzystuje wszystkie funkcje algorytmu najbliższego sąsiada z tą różnicą, iż iteruje po wszystkich wierzchołkach, których jest dokładnie n, dlatego złożoność obliczeniowa tego algorytmu jest równa $O(n^3*logn)$. Złożoność pamięciowa nie ulega zmianom.
\subsection{Algorytm 2-opt}
  Algorytm 2-opt jest algorytmem, który korzysta z własności przestrzeni euklidesowych zwanej nierównością trójkatą. Zauważa, iż jeśli drogi są ze sobą "splecione" to ich rozwinięcie swodouje zmniejszenie funkcji celu. Na tej podstawie posiadając permutację wejściową dokonujemy inwersji pewnej części tablicy w oczekiwaniu, iż doszło do takowych rozplątań.
    \textbf{Złożoność obliczeniowa:}
      Ze względu na występującą pętle while, która wykonuje się do momentu, aż nie natrafimy na ulepszenie aktualnej permutacji bardzo trudno określić złożoność obliczeniową tego algorytmu. Na podstawie testów dla przestrzeni Euklidesowy wnioskujemy, iż ów algorytm może pracować nawet w złożoności $O(n^{3})$. Sytuacja komplikuje się, gdy przechodzimy w przestrzenie, które nie spełniają nierówności trójkątą. Intuicja może nam podpowiadać, iż w tej sytuacji możemy osiągnąć aż wykładniczą złożoność w najgorszym przypadku, jednakże żadne z naszych testów nie potwierdziły tej tezy.
    \textbf{Złożoność pamięciowa:}
      Ze względu na to, iż w procedurze tworzymy jedną listę n elementową przechowującą aktualną permutację, i jedną listę n elementową przechowującą najlepszą permutację, złożoność pamięciowa sprowadza się do O(n).